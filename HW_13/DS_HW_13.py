# -*- coding: utf-8 -*-
"""DS_HW_13.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y46d_ppWcAAZdrtrl-jgKQnv1G4X8a6r

# Домашнє завдання

## Частина 1

В якості домашнього завдання вам пропонується створити нейронну мережу за допомогою механізмів Keras, яка буде класифікувати товари із датасету `fasion_mnist`.

На відміну від попереднього завдання вам пропонується створити згорткову нейромережу. Підберіть архітектуру мережі та навчіть її на даних із датасету `fasion_mnist`. Спробуйте досягти максимально можливої точності класифікації за рахунок маніпуляції параметрами мережі. Порівняйте точність отриманої згорткової мережі з точністю багатошарової мережі з попереднього завдання. Зробіть висновки.

## Частина 2
В цій частині ми знову будемо працювати з датасетом `fasion_mnist`.

На відміну від попереднього завдання вам пропонується створити згорткову нейромережу, що використовує `VGG16` в якості згорткової основи.

Навчіть отриману мережу на даних із датасету `fasion_mnist`. Спробуйте досягти максимально можливої точності класифікації за рахунок маніпуляції параметрами мережі. Під час навчання використовуйте __прийоми донавчання__ та __виділення ознак__.

Порівняйте точність отриманої згорткової мережі з точністю багатошарової мережі з попереднього завдання. Зробіть висновки.

## Imports
"""

# Commented out IPython magic to ensure Python compatibility.


import random
import numpy as np

from keras.datasets import fashion_mnist

from tensorflow.keras.models import Sequential
from skimage.color import gray2rgb

from tensorflow.keras.layers import (
  Conv2D,
  MaxPooling2D,
  Flatten,
  Dense
)

from tensorflow.keras.applications import VGG16
from tensorflow.keras.preprocessing.image import (
  img_to_array,
  array_to_img,
  ImageDataGenerator
)

from sklearn.metrics import (
  classification_report,
  confusion_matrix,
  ConfusionMatrixDisplay,
)

import matplotlib.pyplot as plt
# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive')

# Path to your Google Drive folder
PATH = "/content/drive/My Drive/Colab Notebooks"
# PATH = "https://drive.google.com/drive/folders/10GEaCGQiDwbZzKRI16Ok5BcJArCqQjvb?usp=drive_link"

"""## Load DataSet"""

(train_data, train_labels), (test_data, test_labels) = fashion_mnist.load_data()

class_names = [
  'T-shirt/top',
  'Trouser',
  'Pullover',
  'Dress',
  'Coat',
  'Sandal',
  'Shirt',
  'Sneaker',
  'Bag',
  'Ankle boot'
]

"""### Normalization"""

train_data = train_data.reshape((60000, 28, 28, 1)).astype('float32') / 255
test_data = test_data.reshape((10000, 28, 28, 1)).astype('float32') / 255

"""### Visualization"""

num_images = 10

plt.figure(figsize=(15, 5))
for i in range(num_images):
  plt.subplot(1, num_images, i + 1)
  plt.imshow(train_data[i], cmap=plt.cm.binary)
  plt.title(class_names[train_labels[i]])
  plt.axis('off')
plt.show()

"""## Task 1. Model with Conv2D

### Creating model
"""

conv2d_model = Sequential([
  Conv2D(64, (3, 3), activation="relu", input_shape=(28, 28, 1)),
  Conv2D(64, (3, 3), activation="relu"),
  MaxPooling2D((2, 2)),

  Conv2D(128, (3, 3), activation="relu"),
  Conv2D(128, (3, 3), activation="relu"),
  MaxPooling2D((2, 2)),

  Conv2D(256, (3, 3), activation="relu"),
  MaxPooling2D((2, 2)),

  Flatten(),

  Dense(256, activation="relu"),
  Dense(10, activation="softmax")
])

conv2d_model.summary()

"""### Compile model"""

conv2d_model.compile(
  optimizer = 'adam',
  loss = 'sparse_categorical_crossentropy',
  metrics = ['accuracy']
)

"""### Model training"""

conv2d_history = conv2d_model.fit(
  x = train_data,
  y = train_labels,
  batch_size = 64,
  epochs = 16,
  validation_data = (test_data, test_labels),
  verbose=0
)

conv2d_model.save(f"{PATH}/cnn_model.keras")
print("Model 'cnn_model.keras' saved successfully.")

"""### Model evaluation"""

history_conv2d = conv2d_history.history

epochs = range(1, len(history_conv2d['accuracy']) + 1)

plt.figure(figsize=(12, 6))

# Виведення графіка функції втрат
plt.subplot(1, 2, 1)
plt.plot(epochs, history_conv2d['loss'], 'bo', label='Training loss')
plt.plot(epochs, history_conv2d['val_loss'], 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Виведення графіка точності
plt.subplot(1, 2, 2)
plt.plot(epochs, history_conv2d['accuracy'], 'bo', label='Training acc')
plt.plot(epochs, history_conv2d['val_accuracy'], 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

test_loss, test_acc = conv2d_model.evaluate(test_data,  test_labels, verbose=0)
print(f'Test accuracy: {test_acc*100:.2f}%\nTest loss: {np.round(test_loss, 2)}')

"""### Results

#### Classification report
"""

predictions = conv2d_model.predict(test_data, verbose=0)
predicted_classes = np.argmax(predictions, axis=1)

print(classification_report(test_labels, predicted_classes, target_names = class_names))

"""#### Confusion Matrix"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

class_names = [
  'T-shirt/top',
  'Trouser',
  'Pullover',
  'Dress',
  'Coat',
  'Sandal',
  'Shirt',
  'Sneaker',
  'Bag',
  'Ankle boot'
]

fig, ax = plt.subplots(figsize=(12, 12))
cm = confusion_matrix(test_labels, predicted_classes, labels=range(len(class_names)))
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
disp.plot(cmap='Blues', values_format='d', ax=ax)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

"""#### Test with images"""

random_indices = random.sample(range(len(test_data)), 10)
images = test_data[random_indices]
labels = test_labels[random_indices]

predictions = conv2d_model.predict(images, verbose=0)
predicted_labels = np.argmax(predictions, axis=1)

plt.figure(figsize=(20, 20))
for i in range(10):
    plt.subplot(10, 10, i + 1)
    plt.imshow(images[i].reshape((28, 28)), cmap='gray')
    plt.title(f"True: {class_names[labels[i]]}\nPrediction: {class_names[predicted_labels[i]]}", fontsize = 8)
    plt.axis('off')

plt.show()

correct_predictions = (predicted_labels == labels)
accuracy = sum(correct_predictions) / len(correct_predictions)
print(f"Accuracy with 10 images: {accuracy * 100:.2f}%")

"""## Task 2. Model with VGG16

### Data prepare
"""

# Змінюємо розмір зображень на 48x48 (розмір вхідного зображення для VGG16)
train_data_resized = np.array([img_to_array(array_to_img(img).resize((48, 48))) for img in train_data])
test_data_resized = np.array([img_to_array(array_to_img(img).resize((48, 48))) for img in test_data])

# Розширення до 3 каналів (RGB)
train_data_rgb = np.array([gray2rgb(img.squeeze()) for img in train_data_resized])
test_data_rgb = np.array([gray2rgb(img.squeeze()) for img in test_data_resized])

train_data_rgb.shape, test_data_rgb.shape

"""### Define base model"""

# Завантаження переднього кінця (features extractor) моделі VGG16 без останнього повнозв'язного шару
vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))

vgg16_base.summary()

"""### Define Datagen"""

# Створення генераторів для аугментації даних
datagen = ImageDataGenerator(
  rotation_range=20,
  width_shift_range=0.1,
  height_shift_range=0.1,
  horizontal_flip=True,
  fill_mode='nearest'
)

train_generator = datagen.flow(
  train_data_rgb,
  train_labels,
  batch_size=20,
)

validation_generator = datagen.flow(
  test_data_rgb,
  test_labels,
  batch_size=20,
)

"""### Creating model"""

# "Заморожуємо" ваги згорткових шарів VGG16
vgg16_base.trainable = False

vgg16_model = Sequential([
  vgg16_base,
  Flatten(),
  Dense(512, activation="relu"),
  Dense(10, activation="softmax"),
])

vgg16_model.summary()

"""### Compile model"""

vgg16_model.compile(
  optimizer = 'adam',
  loss = 'sparse_categorical_crossentropy',
  metrics = ['accuracy']
)

"""### Model training"""

vgg16_history = vgg16_model.fit(
  train_generator,
  steps_per_epoch=100,
  epochs=100,
  validation_data=validation_generator,
  validation_steps=50,
  verbose=0
)

vgg16_model.save(f"{PATH}/vgg16_model.keras")
print("Model 'vgg16_model.keras' saved successfully.")

"""### Fine-tuning

#### Creating fine-tuning model
"""

# Розморожуємо кілька верхніх шарів для донавчання
vgg16_base.trainable = True

for layer in vgg16_base.layers[:-2]:
  layer.trainable = False

vgg16_base.summary()

ft_model = Sequential()
ft_model.add(vgg16_base)

for layer in vgg16_model.layers[1:]:
  ft_model.add(layer)

ft_model.summary()

"""#### Compile fine-tuning model"""

ft_model.compile(
  optimizer = 'adam',
  loss = 'sparse_categorical_crossentropy',
  metrics = ['accuracy']
)

"""#### Train fine-tuning model"""

ft_model_history = ft_model.fit(
  train_generator,
  steps_per_epoch=100,
  epochs=100,
  validation_data=validation_generator,
  validation_steps=50,
  verbose=0
)

"""### Model evaluation"""

# Історія тренувань моделі
history_ft_model = ft_model_history.history

# Знаходимо мінімальну кількість епох для уникнення помилки
min_epochs = min(
    len(history_ft_model['loss']),
    len(history_ft_model.get('val_loss', [])),
    len(history_ft_model['accuracy']),
    len(history_ft_model.get('val_accuracy', []))
)

# Генеруємо масив епох
epochs = range(1, min_epochs + 1)

# Обрізаємо дані для відповідності розміру
training_loss = history_ft_model['loss'][:min_epochs]
validation_loss = history_ft_model.get('val_loss', [])[:min_epochs]
training_accuracy = history_ft_model['accuracy'][:min_epochs]
validation_accuracy = history_ft_model.get('val_accuracy', [])[:min_epochs]

plt.figure(figsize=(12, 6))

# Графік функції втрат
plt.subplot(1, 2, 1)
plt.plot(epochs, training_loss, 'bo', label='Training loss')
if validation_loss:
    plt.plot(epochs, validation_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Графік точності
plt.subplot(1, 2, 2)
plt.plot(epochs, training_accuracy, 'bo', label='Training accuracy')
if validation_accuracy:
    plt.plot(epochs, validation_accuracy, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

test_loss, test_acc = ft_model.evaluate(test_data_rgb, test_labels, verbose=0)
print(f'Test accuracy: {test_acc*100:.2f}%\nTest loss: {np.round(test_loss, 2)}')

"""### Results

#### Classification report
"""

predictions = ft_model.predict(test_data_rgb, verbose=0)
predicted_classes = np.argmax(predictions, axis=1)

print(classification_report(test_labels, predicted_classes, target_names = class_names))

"""#### Confusion Matrix"""

fig, ax = plt.subplots(figsize=(12, 12))
cm = confusion_matrix(test_labels, predicted_classes, labels=range(len(class_names)))
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
disp.plot(cmap='Blues', values_format='d', ax=ax)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

"""#### Test with images"""

random_indices = random.sample(range(len(test_data_rgb)), 10)
images = test_data_rgb[random_indices]
labels = test_labels[random_indices]

predictions = ft_model.predict(images, verbose=0)
predicted_labels = np.argmax(predictions, axis=1)

plt.figure(figsize=(20, 20))
for i in range(10):
    plt.subplot(10, 10, i + 1)
    plt.imshow(images[i].reshape((48, 48, 3)).astype('uint8'), cmap='gray')
    plt.title(f"True: {class_names[labels[i]]}\nPrediction: {class_names[predicted_labels[i]]}", fontsize = 8)
    plt.axis('off')

plt.show()

correct_predictions = (predicted_labels == labels)
accuracy = sum(correct_predictions) / len(correct_predictions)
print(f"Accuracy with 10 images: {accuracy * 100:.2f}%")

"""# Висновки

У порівнянні з багатошаровою нейронною мережею, згорткова, що включає шари   __Conv2D__ та __MaxPooling2D__ дає більшу точність за набагато меншого розміру самої моделі.
"""